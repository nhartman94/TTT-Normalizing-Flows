{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dce70f-aead-4ec3-8da3-27c51d6f8e14",
   "metadata": {},
   "source": [
    "# Conditional Real-NVPs\n",
    "\n",
    "**Goal:** Extend the Real-NVP model we built in `Real-NVP-tutorial` to make it conditional, i.e, a model for $p_\\theta(x|y)$.\n",
    "\n",
    "![](flow-graphic.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56509fd8-7bc7-4334-93a7-96891a19e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59724b37-84a4-4cfb-9aa2-38c9f49582de",
   "metadata": {},
   "source": [
    "## First, some preliminaries copied over from the other nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e735dc-b5c7-4cab-9018-2157a9dbb505",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28601f80-bd51-49e3-9747-3113e7ed09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 30_000\n",
    "noise = 0.05\n",
    "X = make_moons(nsamples, noise=noise)[0]\n",
    "\n",
    "X_torch = torch.Tensor(X).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696d2a0-9521-4289-b7c6-c9ca99fa1679",
   "metadata": {},
   "source": [
    "**Hyperparameters and settings from the previous noteboook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3633f-2913-4a09-a20a-9324e5485604",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks=9\n",
    "num_hidden=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94920430-33e7-4c48-aec7-49cd5e38f080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for a GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device='cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc001a0-0f4f-4eaf-af4a-7c9e45aca4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "nTrain=24_000\n",
    "nVal=3_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97de27-4828-4b9d-a217-b50a8d38f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 4, 'pin_memory': True}  if torch.cuda.is_available() else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f61690-45ae-4905-aafc-70aca4cec9e8",
   "metadata": {},
   "source": [
    "**Extended functionality to draw the model results with a conditional input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932d869-1387-4240-8fd6-e776eb31aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_model(model, cond_input=None, title=''):\n",
    "    '''\n",
    "    Goal: Given the given model weights, show\n",
    "    (1) The density\n",
    "    (2) Samples from p_X(x)\n",
    "    \n",
    "    Inputs:\n",
    "    - model that we're plotting the density of\n",
    "    - cond_input: Extra logic for the conditional gen model\n",
    "                  (bonus prob)\n",
    "    - title: Super title over 2 subfigs\n",
    "    '''\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4),\n",
    "                                  gridspec_kw={'hspace':10})\n",
    "\n",
    "    # Title the plot with the log(p) on the validation set\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    '''\n",
    "    (1) Plot the density\n",
    "    '''\n",
    "    x = np.linspace(-1,2)\n",
    "    y = np.linspace(-.75,1.25)\n",
    "\n",
    "    xx,yy = np.meshgrid(x,y)\n",
    "\n",
    "    X_grid = np.vstack([xx.flatten(),yy.flatten()]).T.astype(np.float32)\n",
    "    X_grid.T\n",
    "\n",
    "    X_grid = torch.tensor(X_grid).to(device)\n",
    "\n",
    "    if cond_input:\n",
    "        # For last (bonus) prob\n",
    "        y0,y1 = cond_input\n",
    "        Y_grid = torch.ones_like(X_grid).to(device)\n",
    "        Y_grid[:,0] = y0\n",
    "        Y_grid[:,1] = y1\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            log_probs = model.log_probs(X_grid,Y_grid).cpu().numpy()\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            log_probs = model.log_probs(X_grid).cpu().numpy()\n",
    "\n",
    "    ax1.pcolormesh(xx,yy,np.exp(log_probs.reshape(50,50)),shading='auto',cmap='coolwarm')\n",
    "\n",
    "    ax1.set_xlabel('$X_0$',fontsize=12)\n",
    "    ax1.set_ylabel('$X_1$',fontsize=12)\n",
    "\n",
    "    '''\n",
    "    (2) Plot samples from the model\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if cond_input:\n",
    "            # For last (bonus) prob\n",
    "            Y_con = torch.ones(500,2).to(device)\n",
    "            Y_con[:,0] = y0\n",
    "            Y_con[:,1] = y1\n",
    "            X_gen = model.sample(Y_con).cpu().numpy()\n",
    "        else:\n",
    "            X_gen = model.sample(500).cpu().numpy()\n",
    "        \n",
    "    ax2.scatter(*X_gen.T)\n",
    "\n",
    "    ax2.set_xlabel('$X_0$',fontsize=12)\n",
    "    ax2.set_ylabel('$X_1$',fontsize=12)\n",
    "\n",
    "    ax2.set_xlim(x[[0,-1]])\n",
    "    ax2.set_ylim(y[[0,-1]])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8189258-be50-43b0-b85e-761b2714b4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85eabff-b65d-4dea-b37a-891e2ce7c023",
   "metadata": {},
   "source": [
    "# Bonus: Conditional flow\n",
    "\n",
    "Lots of applications in science involve conditional flow models, can you extend our the model we built here to be conditioned on the center point for the moon? \n",
    "\n",
    "**Plan:** \n",
    "- Train sampling moon density centers $y \\in \\mathbb{R}^2$ **uniformly** from [0,1]\n",
    "\n",
    "Recall, we were training the 30k training samples for modelling 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f41476-7a75-4633-9972-96d903aad439",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X.shape[1]\n",
    "\n",
    "Y = torch.Tensor(nsamples, num_inputs).uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c71f8-bf3e-406b-8023-3078180d6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cond = X_torch + Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93a15b-eba1-4d9d-92aa-925d096f2e80",
   "metadata": {},
   "source": [
    "**Let's look at the prediction for some slices of the conditional output**\n",
    "- $0 < y_0, y_1 < .05$ \n",
    "- $0.5 < y_0, y_1 < .55$ \n",
    "- $0.95 < y_0, y_1 < 1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c475180-7ecc-4091-92b2-8dc75a9d3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = .05\n",
    "for i,y_min in enumerate([0,.5,1-dy]):\n",
    "    \n",
    "    y_max = y_min+dy\n",
    "    mi = (Y[:,0] > y_min) & (Y[:,0] < y_max)\n",
    "    mi = mi & (Y[:,1] > y_min) & (Y[:,1] < y_max)\n",
    "    \n",
    "    y_avg = .5 * (y_min + y_max)\n",
    "    \n",
    "    c=f'C{i}'\n",
    "    plt.scatter(*X_cond[mi].T.numpy(),alpha=.5,color=c)\n",
    "    plt.scatter([y_avg],[y_avg],250,marker='x',label='avg center',color=c)\n",
    "    plt.xlabel('$X_0$',fontsize=18)\n",
    "    plt.ylabel('$X_1$',fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.title(f'$y_0,y_1$ center in ({y_min},{y_max})')\n",
    "    \n",
    "    plt.xlim(-1.2,3.2)\n",
    "    plt.ylim(-.7,2.2)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ab76b-2f5a-441f-8668-76cf34819aa3",
   "metadata": {},
   "source": [
    "### TO DO: Implement the conditional flow model\n",
    "\n",
    "**Hint 1:** Extend the coupling layer to a conditional coupling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03202eff-c689-4f4b-9bd8-b5356c330717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondCouplingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_cond_inputs, num_hidden, mask):\n",
    "        super(CondCouplingLayer, self).__init__()\n",
    "\n",
    "        '''\n",
    "        TO DO: Fill in \n",
    "        (Tip: look at `Coupling layer` for inspiration)\n",
    "        '''\n",
    "\n",
    "    def forward(self, inputs, cond_inputs,  mode='forward'):\n",
    "        \n",
    "        mask = self.mask\n",
    "        masked_inputs = inputs * mask\n",
    "        \n",
    "        all_inputs = torch.cat([masked_inputs, cond_inputs],axis=1)\n",
    "        \n",
    "        if mode == 'forward':\n",
    "            \n",
    "            '''\n",
    "            TO DO : Fill in \n",
    "            '''\n",
    "            raise NotImplementedError  \n",
    "                \n",
    "        else:\n",
    "            \n",
    "            '''\n",
    "            TO DO : Fill in \n",
    "            '''\n",
    "            raise NotImplementedError  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ac38e-6fc5-4508-948f-f83a27a714b8",
   "metadata": {},
   "source": [
    "**Hint 2:** Implement a `CondFlowSequential` class that calls the `CondCouplingLayer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea20b1-f828-4c31-a9c9-7de0e30bcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondFlowSequential(nn.Sequential):\n",
    "    \"\"\" A sequential container for flows extending the \n",
    "    FlowSequential class for conditional inputs\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, inputs, cond_inputs, mode='forward'):\n",
    "        \"\"\" Performs a forward or reverse pass for flow modules.\n",
    "        Args:\n",
    "            inputs: a tuple of inputs and logdets\n",
    "            cond_inputs: The conditional inputs to the flow\n",
    "            mode: to run direct computation or inverse\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def log_probs(self, inputs, cond_inputs):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def sample(self, cond_inputs, num_samples=None):\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af877d7d-ec25-4631-aa5c-c970fec0ca3a",
   "metadata": {},
   "source": [
    "**Put the pieces together to define a flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c65a3-7b6c-4980-babc-c7536336a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extending the code that we had before\n",
    "num_cond_inputs = Y.shape[1]\n",
    "\n",
    "mask = torch.arange(0, num_cond_inputs) % 2\n",
    "mask = mask.to(device).float()\n",
    "\n",
    "modules=[]\n",
    "for _ in range(num_blocks):\n",
    "    modules.append( CondCouplingLayer( num_inputs, num_cond_inputs, num_hidden, mask) )\n",
    "    mask = 1 - mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c7b96-048b-4a1e-8c84-37f5d6f7b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To DO: Define the conditional flow from these modules\n",
    "cond_flow = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ed817-a4e9-4e99-9f59-fcd7af971784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've defined the model... put it on the gpu\n",
    "cond_flow = cond_flow.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a77025-e17e-4586-964d-0761f9054f3a",
   "metadata": {},
   "source": [
    "**Training code**\n",
    "\n",
    "It's the same as before, just evaluating the conditional generative model, so we'll just give you the training functions.\n",
    "\n",
    "We'll just use a `from torch.utils.data.Dataset` first to pass to the `DataLoaders` that we'll create :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2adfda-6efa-4bd4-bfe5-ca570717b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "New dataset class to deal w/ the tuple of X,Y input\n",
    "'''\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CondMoonsDataset(Dataset):\n",
    "    '''\n",
    "    Skeleton class taken from:\n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    '''\n",
    "    def __init__(self,nExamples,noise=0.05):\n",
    "        \n",
    "        X_np = make_moons(nExamples, noise=noise)[0]\n",
    "        X = torch.Tensor(X_np).float()\n",
    "            \n",
    "        num_inputs = X.shape[1]\n",
    "        Y = torch.Tensor(nExamples, num_inputs).uniform_()\n",
    "         \n",
    "        X = X+Y\n",
    "            \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0375ae1-3461-4c12-a4b0-43141bdc2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_train_loader = torch.utils.data.DataLoader(\n",
    "    CondMoonsDataset(nTrain), \n",
    "    batch_size=batch_size, shuffle=True,**kwargs)\n",
    "\n",
    "cond_valid_loader = torch.utils.data.DataLoader(\n",
    "    CondMoonsDataset(nVal),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CondMoonsDataset(nVal),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce6336-8ad4-491e-aea1-ed5c76e96ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_train(model, train_loader, opt):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (X,Y) in enumerate(train_loader):\n",
    "        \n",
    "        X = X.to(device) \n",
    "        Y = Y.to(device) \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        loss = -model.log_probs(X,Y).mean()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def cond_validate(model, loader, prefix='Validation'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    for batch_idx, (X,Y) in enumerate(loader):\n",
    "\n",
    "        X = X.to(device) \n",
    "        Y = Y.to(device) \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            val_loss += -model.log_probs(X,Y).sum().item()  # sum up batch loss\n",
    "     \n",
    "    val_loss /= len(loader.dataset)\n",
    "    return val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c1e64-8073-4faa-9c9a-52c6f0b1b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "opt = torch.optim.Adam(cond_flow.parameters(), lr=lr, weight_decay=1e-6)\n",
    "\n",
    "epochs=81\n",
    "\n",
    "cond_train_losses = np.zeros(epochs)\n",
    "cond_val_losses = np.zeros(epochs)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    cond_train_losses[i] = cond_train(cond_flow, cond_train_loader, opt)\n",
    "    cond_val_losses[i] = cond_validate(cond_flow, cond_valid_loader)\n",
    "\n",
    "    print(f'Epoch {i}: train loss = {cond_train_losses[i]:.4f}, val loss = {cond_val_losses[i]:.4f}')\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        # Draw the model prediction\n",
    "        draw_model(cond_flow,cond_input=[0,0],\n",
    "                   title=f'Validation loss = {cond_val_losses[i]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9a67b-4b42-404d-87bc-49e183054d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec497e0-eba1-4714-812e-0bf12ad38be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Plot the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534eba70-ea77-49da-b4a4-0f083e160d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "640a574c-bc96-4002-9846-da7c8d856e12",
   "metadata": {},
   "source": [
    "**Sanity check:** What have we learned about crescent moons in the three cases that we had above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e004d-99ea-4ac6-bb5c-1bc9a74b9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(12,3),\n",
    "                            gridspec_kw={'wspace':.3})\n",
    "\n",
    "fig.suptitle('Conditional flow')\n",
    "\n",
    "# Define the density grid\n",
    "x = np.linspace(-1.2,3.2)\n",
    "y = np.linspace(-.7,2.2)\n",
    "\n",
    "xx,yy = np.meshgrid(x,y)\n",
    "\n",
    "X_grid = np.vstack([xx.flatten(),yy.flatten()]).T.astype(np.float32)\n",
    "X_grid.T\n",
    "\n",
    "X_grid = torch.tensor(X_grid).to(device)\n",
    "\n",
    "'''\n",
    "Loop over the centers\n",
    "'''\n",
    "for yi,ax,cmap in zip([0, 0.5, 1],axs,['Blues','Oranges','Greens']):\n",
    "    \n",
    "    # Plot the density\n",
    "    \n",
    "    Y_grid = torch.ones_like(X_grid).to(device)\n",
    "    Y_grid[:,0] *= yi\n",
    "    Y_grid[:,1] *= yi\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        log_probs = cond_flow.log_probs(X_grid,Y_grid).cpu().numpy()\n",
    "\n",
    "    ax.pcolormesh(xx,yy,np.exp(log_probs.reshape(50,50)),shading='auto',cmap=cmap)\n",
    "\n",
    "    ax.set_xlabel('$X_0$',fontsize=12)\n",
    "    ax.set_ylabel('$X_1$',fontsize=12)\n",
    "\n",
    "    ax.scatter([yi],[yi],300,marker='x',color='k')\n",
    "    # break\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af543b4-26fa-4e6e-8d1a-ef3ff75eb203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "453b6b8b-5b2c-47f2-a73a-088aa5a34aab",
   "metadata": {},
   "source": [
    "**Resources:**\n",
    "- This tutorial for the code in this repo came from the [pytorch-flows](https://github.com/ikostrikov/pytorch-flows) repo.\n",
    "- The [nflows](https://github.com/bayesiains/nflows.git) is also a very nice package that includes the Real-NVP model and also the RQ-NSF that we also talked about in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dc6cf-fb65-429a-9119-648d6095b2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
